---
title: "Multiple Linear Regression: Predicting Rent Prices"
date: 2020-04-03
tags: [Regression, Data Exploration, Transformations]
header: 
excerpt: "Building out a MLR model to Predict Rent in Brazil"
---

# Predicting Brazilian Rent Prices
## An application of Multiple Linear Regression


### Loading the data

The data used in this project is downloaded from Kaggle. You can find
the data
[here](https://www.kaggle.com/rubenssjr/brasilian-houses-to-rent/version/2).

    library(readxl)
    df <- read_xlsx('rent_brazil.xlsx')

    ## New names:
    ## * `` -> ...1

    df.copy <- df
    head(df)

    ## # A tibble: 6 x 14
    ##    ...1  city  area rooms bathroom `parking spaces` floor animal furniture hoa  
    ##   <dbl> <dbl> <dbl> <dbl>    <dbl>            <dbl> <chr> <chr>  <chr>     <chr>
    ## 1     0     1   240     3        3                4 -     acept  furnished R$0  
    ## 2     1     0    64     2        1                1 10    acept  not furn… R$540
    ## 3     2     1   443     5        5                4 3     acept  furnished R$4,…
    ## 4     3     1    73     2        2                1 12    acept  not furn… R$700
    ## 5     4     1    19     1        1                0 -     not a… not furn… R$0  
    ## 6     5     1    13     1        1                0 2     acept  not furn… R$0  
    ## # … with 4 more variables: `rent amount` <chr>, `property tax` <chr>, `fire
    ## #   insurance` <chr>, total <chr>

### Data Cleaning

By calling head on this imported dataframe we observe 14 columns with 13
variables. The first column is an ID column vector that has no impact on
the rent amount, therefore we will omit it. We can also omit the column
vectors ‘hoa’, ‘property tax’, ‘fire insurance’ and ‘total’ as these
variables represent the additional payments to rent that make up the
total cost and do not predict rent, the target variable.

    #We do this by passing through a vector of the columns that we wish to omit preceded by a minus sign. 
    df <- df[,-c(1, 10, 12:14)]
    head(df)

    ## # A tibble: 6 x 9
    ##    city  area rooms bathroom `parking spaces` floor animal furniture
    ##   <dbl> <dbl> <dbl>    <dbl>            <dbl> <chr> <chr>  <chr>    
    ## 1     1   240     3        3                4 -     acept  furnished
    ## 2     0    64     2        1                1 10    acept  not furn…
    ## 3     1   443     5        5                4 3     acept  furnished
    ## 4     1    73     2        2                1 12    acept  not furn…
    ## 5     1    19     1        1                0 -     not a… not furn…
    ## 6     1    13     1        1                0 2     acept  not furn…
    ## # … with 1 more variable: `rent amount` <chr>

We now have the variables that we need, they are not the correct data
types; we must clean these up. To get a better idea of the issues, we
call structure.

    str(df)

    ## Classes 'tbl_df', 'tbl' and 'data.frame':    6080 obs. of  9 variables:
    ##  $ city          : num  1 0 1 1 1 1 1 1 1 1 ...
    ##  $ area          : num  240 64 443 73 19 13 55 55 82 32 ...
    ##  $ rooms         : num  3 2 5 2 1 1 1 2 3 1 ...
    ##  $ bathroom      : num  3 1 5 2 1 1 1 2 1 1 ...
    ##  $ parking spaces: num  4 1 4 1 0 0 1 1 1 1 ...
    ##  $ floor         : chr  "-" "10" "3" "12" ...
    ##  $ animal        : chr  "acept" "acept" "acept" "acept" ...
    ##  $ furniture     : chr  "furnished" "not furnished" "furnished" "not furnished" ...
    ##  $ rent amount   : chr  "R$8,000" "R$820" "R$7,000" "R$1,250" ...

First we will change categorical variables into factors.

    df$city <- as.numeric(factor(df$city, levels = c(0,1), labels = c(1:2)))
    df$animal <- as.numeric(factor(df$animal, levels = c("acept", "not acept"), labels = c(1:2)))
    df$furniture <- as.numeric(factor(df$furniture, levels = c("furnished", "not furnished"), labels = c(1:2)))

    head(df)

    ## # A tibble: 6 x 9
    ##    city  area rooms bathroom `parking spaces` floor animal furniture
    ##   <dbl> <dbl> <dbl>    <dbl>            <dbl> <chr>  <dbl>     <dbl>
    ## 1     2   240     3        3                4 -          1         1
    ## 2     1    64     2        1                1 10         1         2
    ## 3     2   443     5        5                4 3          1         1
    ## 4     2    73     2        2                1 12         1         2
    ## 5     2    19     1        1                0 -          2         2
    ## 6     2    13     1        1                0 2          1         2
    ## # … with 1 more variable: `rent amount` <chr>

Now we must address the floor variable. No other information is provided
with the variable from the dataset owner. We have a few options with
what to do with the entries that have - in them instead of a number. We
can: 1. Omit the entries 2. Replace entries with the mean of the other
values. 3. Replace the entries with the median if the other values.

Let’s see how many entries do not have full information.

    library(dplyr)

    ## 
    ## Attaching package: 'dplyr'

    ## The following objects are masked from 'package:stats':
    ## 
    ##     filter, lag

    ## The following objects are masked from 'package:base':
    ## 
    ##     intersect, setdiff, setequal, union

    df$floor <- na_if(df$floor, "-")
    sum(is.na(df$floor))/length(df$floor)

    ## [1] 0.2557566

    df_all <- df

There are 1,555 or 25% of enteries with null values in our floor
variable. This is not a negliable number. Replacing that many values
with an average will skew and lessen the explanatory power of that
variable. I am making the decision to omit the enteries without a floor
assigned to them to understand the impact that floor has on rent in
Brazil. If we find that floor does not have significant explanatory
power, I will omit the variable in our regression and run the regression
with all of the data points.

    df <- na.omit(df)
    df$floor <- as.numeric(df$floor)

    df_all$floor <- as.numeric(df_all$floor)

    str(df)

    ## Classes 'tbl_df', 'tbl' and 'data.frame':    4525 obs. of  9 variables:
    ##  $ city          : num  1 2 2 2 2 2 2 2 1 1 ...
    ##  $ area          : num  64 443 73 13 55 55 82 32 60 64 ...
    ##  $ rooms         : num  2 5 2 1 1 2 3 1 1 1 ...
    ##  $ bathroom      : num  1 5 2 1 1 2 1 1 1 2 ...
    ##  $ parking spaces: num  1 4 1 0 1 1 1 1 0 1 ...
    ##  $ floor         : num  10 3 12 2 2 2 3 16 6 4 ...
    ##  $ animal        : num  1 1 1 1 1 1 1 1 1 1 ...
    ##  $ furniture     : num  2 1 2 2 1 2 1 2 2 1 ...
    ##  $ rent amount   : chr  "R$820" "R$7,000" "R$1,250" "R$2,200" ...
    ##  - attr(*, "na.action")= 'omit' Named int  1 5 17 18 21 24 30 32 33 36 ...
    ##   ..- attr(*, "names")= chr  "1" "5" "17" "18" ...

We now observe that the dataframe has 4525 entries, or 6080 of the
original enteries minus the 1555 enteries that had NA values in the
floor variable.

Lastly, we clean ‘rent amount’.

    df$`rent amount` <- sub(',','', df$`rent amount`)
    df$`rent amount` <- sub('R','', df$`rent amount`)
    df$`rent amount` <-as.numeric(gsub("\\$", "", df$`rent amount`))

    df_all$`rent amount` <- sub(',','', df_all$`rent amount`)
    df_all$`rent amount` <- sub('R','', df_all$`rent amount`)
    df_all$`rent amount` <-as.numeric(gsub("\\$", "", df_all$`rent amount`))

    str(df)

    ## Classes 'tbl_df', 'tbl' and 'data.frame':    4525 obs. of  9 variables:
    ##  $ city          : num  1 2 2 2 2 2 2 2 1 1 ...
    ##  $ area          : num  64 443 73 13 55 55 82 32 60 64 ...
    ##  $ rooms         : num  2 5 2 1 1 2 3 1 1 1 ...
    ##  $ bathroom      : num  1 5 2 1 1 2 1 1 1 2 ...
    ##  $ parking spaces: num  1 4 1 0 1 1 1 1 0 1 ...
    ##  $ floor         : num  10 3 12 2 2 2 3 16 6 4 ...
    ##  $ animal        : num  1 1 1 1 1 1 1 1 1 1 ...
    ##  $ furniture     : num  2 1 2 2 1 2 1 2 2 1 ...
    ##  $ rent amount   : num  820 7000 1250 2200 5000 1300 2000 2900 720 1550 ...
    ##  - attr(*, "na.action")= 'omit' Named int  1 5 17 18 21 24 30 32 33 36 ...
    ##   ..- attr(*, "names")= chr  "1" "5" "17" "18" ...

Data cleaning is complete.

### Exploratory data analysis

I am interested on the correlation between all of the features here and
wish to view a summary of how they are all related. A corrplot will do
fine.

    library(corrplot)

    ## corrplot 0.84 loaded

    M <- cor(df)
    corrplot(M, method = "circle")

<img src="{{ site.url }}{{ site.baseurl }}/images/corrplot.png" alt="">

Some rther interesting correlations. More analysis needed. I want to
know the distributions of a few of these variables, specifically parking
spaces, floors, area, rooms, bathrooms and rent amount.

    par(mfrow=c(3,3))
    a <- (df$area)
    r<- (df$rooms)
    b <- (df$bathroom)
    f <- (df$floor)
    ra <- (df$`rent amount`)
    ps<- (df$`parking spaces`)

    hist(a, main = "Area histogram")
    hist(r, main = "Rooms histogram")
    hist(b, main = "Bathrooms histogram")
    hist(f, main = "Floor histogram")
    hist(ra, main = "Rent amount histogram")
    hist(ps, main = "Parking Spaces histogram")

<img src="{{ site.url }}{{ site.baseurl }}/images/histograms1.png" alt="">

From the density plots, it is obvious that some of the features are
skewed right. This may present an issue as an assumption of regression
is that the features are normally distributed. However, there are over
30 observations so the central limit theorem does apply. A log
transformation is not a bad idea here. Let’s view the distributions
again after this transformation.

    par(mfrow=c(3,3))
    hist(log(a), main = "Log Transformation Area histogram")
    hist(r, main = "Rooms histogram")
    hist(b, main = "Bathrooms histogram")
    hist(log(f), main = "Log Transformation Floor histogram")
    hist(log(ra), main = "Log Transformation Rent amount histogram")
    hist(ps, main = "Parking Spaces histogram")

<img src="{{ site.url }}{{ site.baseurl }}/images/histograms2.png" alt="">

These historgram look much more approximately normal. We will go ahead
and execute these transformations.

    df$area <- log(df$area)
    df$floor <- log(df$floor)
    df$`rent amount` <- log(df$`rent amount`)

    #Note that we are transforming both our dependent and independent variables. This will have an implication on how we read out our final results. 

Personally, I am most interested in the relationship that area and price
have. If it is linear or if it is polynomic in its relation I do not
know. A scatterplot will help decipher this question.

    plot(df$area,df$`rent amount`)

<img src="{{ site.url }}{{ site.baseurl }}/images/plot 1.png" alt="">

Due two two outliers, we cannot obtain the information we wanted. To fix
this, we will limit the x-axis to less than 8 log(square feet). We will
add a trend line, too.

    library(ggplot2)

    ggplot(df, aes(area, `rent amount`)) + 
      geom_point() + 
      geom_smooth(method = "lm") +
      xlim(0,8) +
      ylab("Rent Amount")+
      xlab("Square footage") +
      ggtitle("Scatter Plot: Area vs Rent Amount")+
      theme_bw()

    ## `geom_smooth()` using formula 'y ~ x'

    ## Warning: Removed 2 rows containing non-finite values (stat_smooth).

    ## Warning: Removed 2 rows containing missing values (geom_point).

<img src="{{ site.url }}{{ site.baseurl }}/images/linear plot.png" alt="">

The scatter plot shows gives us a rather convincing linear relationship.

### Multiple Linear Regression

First we will split the data set randomly into a test and train set.

    library(caTools)
    set.seed(123)
    split = sample.split(df$`rent amount`, SplitRatio = 0.8)
    training_set = subset(df, split == TRUE)
    test_set = subset(df, split == FALSE)

We have succesfully split the dataset into training and testing data.
Now it is time to use the training set to create our regression.

    MLRmodel <- lm(`rent amount`~., df)

We have exectued our model. Let’s examine the summary.

    summary(MLRmodel)

    ## 
    ## Call:
    ## lm(formula = `rent amount` ~ ., data = df)
    ## 
    ## Residuals:
    ##      Min       1Q   Median       3Q      Max 
    ## -2.38911 -0.30331 -0.00269  0.30901  2.39970 
    ## 
    ## Coefficients:
    ##                   Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)       4.829000   0.082283  58.688   <2e-16 ***
    ## city              0.601270   0.019861  30.274   <2e-16 ***
    ## area              0.525841   0.018996  27.681   <2e-16 ***
    ## rooms            -0.100266   0.012112  -8.278   <2e-16 ***
    ## bathroom          0.112275   0.009886  11.357   <2e-16 ***
    ## `parking spaces`  0.083873   0.008607   9.745   <2e-16 ***
    ## floor             0.069413   0.007595   9.140   <2e-16 ***
    ## animal            0.030621   0.015944   1.921   0.0549 .  
    ## furniture        -0.332104   0.015008 -22.129   <2e-16 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 0.4513 on 4516 degrees of freedom
    ## Multiple R-squared:  0.6498, Adjusted R-squared:  0.6491 
    ## F-statistic:  1047 on 8 and 4516 DF,  p-value: < 2.2e-16

Not bad! An addjusted R-squared value of .6491 shows that the features
we have explain about 65% of rent amounts in brazil. The feature animals
has a p-value of of .0549. This implies that they are not significant at
an alpha value of .05 but would be at .1. Removing it may inject omitted
variable bias into our model. This would be a worse outcome than leaving
it in.

The interpretation of the coefficients here is crucial to understanding
the model. If they are not interpreted correctly, the model is useless.
Because we took log transformations of some variables, we interpret the
coefficients in a different manner. For a more extensive look into this,
look up log-level, level-log, or log-log model.

I beleive that the chart found on this
[website](https://sites.google.com/site/curtiskephart/ta/econ113/interpreting-beta)
is a thorough and easy to understand walk through of this topic.

Now, let us use the model to predict the rent amounts on the test data.

    predictions <- predict.lm(MLRmodel, test_set[,-9])
    results <- cbind.data.frame(predictions, test_set[,9])
    plot(results$predictions, results$`rent amount`)

<img src="{{ site.url }}{{ site.baseurl }}/images/last plot.png" alt="">

Now we need a metric to judge our predictions on. In this case I will
use RSME which stands for residual mean squared error.

    sqrt(mean(predictions - results$`rent amount`)**2)

    ## [1] 0.007138436

RSME is a difficult metric to guage as there is no absolute “good” or
“bad” result. It is relative to the dependent variable. The dependent
variable here was between 0-10 and thus an RSME of .007138 is pretty
good. Also, the strong linearity at a 45 degree angle in the results
verus predictions plot also signifies that it is a good model.